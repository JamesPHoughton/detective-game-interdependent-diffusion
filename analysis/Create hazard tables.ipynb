{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Hazard Tables\n",
    "This notebook creates hazard tables to use in cox regression. It creates one hazard table per block (so there is a matching data json file). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%pylab inline\n",
    "from helpers import retrace\n",
    "import json\n",
    "import copy\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_n_triangle_paths(M, edge):\n",
    "    \"\"\" Fast check for triangle closing rule\"\"\"\n",
    "    try:\n",
    "        from_neighbors = set(M[edge[0]])  # if concept 0 not in network, false\n",
    "        to_neighbors = set(M[edge[1]])  # if concept 1 not in network, false\n",
    "        return len(from_neighbors & to_neighbors)  # closes number of existing paths\n",
    "    except:\n",
    "        return 0\n",
    "\n",
    "\n",
    "def instantaneous_hazard_factors(game, g, t):\n",
    "    \"\"\"\n",
    "    Given the state of the game, what are the factors influencing the hazard of adopting all beliefs?\n",
    "\n",
    "    Returns a row for the hazard factors of all individuals for adopting all beliefs \n",
    "    given the current state of the game. Gets big fast.\n",
    "    \"\"\"\n",
    "    prompt_nodes = set(game['data.clues']['tclue_1_2']['nodes'])\n",
    "\n",
    "    rows = []\n",
    "    for player_id, player_data in game['players'].items():\n",
    "\n",
    "        pos = player_data['data.position']\n",
    "        M = g.nodes()[player_id]['M']  # promising leads (memory)\n",
    "        F = g.nodes()[player_id]['F']  # dead ends (forgetory)\n",
    "\n",
    "        for clue_id, clue_data in game['data.clues'].items():\n",
    "            if clue_id[0] == pos[0]: # only collect treatment clues for treatment players & vice versa\n",
    "                \n",
    "                nodes = set(clue_data['nodes'])\n",
    "                row = {\n",
    "                    'start': t,\n",
    "                    \n",
    "                    'exposure_id': '%s_%s'%(player_id, clue_id),  # to group all rows corresponding to same exposure \n",
    "                    'player_id': player_id,  # player random effect\n",
    "                    'game_id': game['_id'],  # game random effect\n",
    "    \n",
    "                    'is_treatment_condition': pos.startswith('t'),\n",
    "                    'is_spoke': len(nodes.intersection(prompt_nodes)) == 1,\n",
    "                    'is_link_or_spur': len(nodes.intersection(prompt_nodes)) == 0,\n",
    "                    'is_prompt': nodes == prompt_nodes,\n",
    "                    'is_in_leads': M.has_edge(*nodes),\n",
    "                    'is_in_deads': F.has_edge(*nodes),\n",
    "                    \n",
    "                    'n_exposures': sum([g.nodes()[nid]['M'].has_edge(*nodes) for nid in g.neighbors(player_id)]),  # number of neighbors exposing\n",
    "\n",
    "                    # number of beliefs already adopted\n",
    "                    'n_existing_leads': M.number_of_edges(),\n",
    "                    \n",
    "#                    'n_fresh_candidates': ... # expensive, and not very influential \n",
    "                    # dummies for the time block\n",
    "                    'in_startup':    t<30,   # reading newly available clues\n",
    "                    'in_peak':   30<=t<180,  # most active time\n",
    "                    'in_tail':  180<=t<420,  # less active time\n",
    "                    'in_close': 420<=t,      # last minute, running out of time\n",
    "                    \n",
    "                    # number of connections by any clue to any of the rim nodes\n",
    "                    'n_rim_connections': sum([v for k,v in M.degree(nodes-prompt_nodes)]),  # includes the current clue, if it exists\n",
    "                    \n",
    "                    # number of triangle paths\n",
    "                    'n_triangle_paths': fast_n_triangle_paths(M, clue_data['nodes']),\n",
    "                    \n",
    "                    # number of beliefs that the player has that are also in the exposers' leads\n",
    "                    'n_edges_shared_with_exposers': len({\n",
    "                        edge for nid in g.neighbors(player_id) \n",
    "                        if g.nodes()[nid]['M'].has_edge(*nodes) \n",
    "                        for edge in g.nodes()[nid]['M'].edges()\n",
    "                    }.intersection({edge for edge in M.edges()})), \n",
    "#                    'n_spoke_connections': ... # todo. \n",
    "#                    'n_link_or_spur_connections': \n",
    "                }\n",
    "                row['is_link'] = row['is_link_or_spur'] & row['is_treatment_condition']\n",
    "                row['is_spur'] = row['is_link_or_spur'] & ~row['is_treatment_condition']                \n",
    "                rows.append(row)\n",
    "\n",
    "    return rows\n",
    "\n",
    "\n",
    "def process_exposure_group(group, t_last):\n",
    "    \"\"\"\n",
    "    Groups represent player-clue combinations, or unique \"exposure\" possibilities\n",
    "    Takes the hazard table and creates a table that lifelines can use.\n",
    "    1. Condenses multiple rows (by dropping duplicates)\n",
    "    2. Treats start and end times\n",
    "    3. Identifies adoption events\n",
    "    \"\"\"\n",
    "    \n",
    "    # discard player-clue groups where the player is never exposed to the clue\n",
    "    if max(group['n_exposures']) == 0: \n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    # check that group is sorted\n",
    "    group.sort_values(['start'], inplace=True)\n",
    "    \n",
    "    # drop consecutive duplicate rows (ie, nothing changes w.r.t. the adoption factors)\n",
    "    match_on_cols = set(group.columns) - {'start'}\n",
    "    keep_rows = (group[match_on_cols].shift() != group[match_on_cols]).any(axis=1)\n",
    "    group = group.loc[keep_rows]\n",
    "\n",
    "    # identify exposures where the player is exposed at start\n",
    "    # the player may react differently to these than others\n",
    "    group['is_exposed_t0'] = (group[group['start']<3]['n_exposures'] > 0).any()\n",
    "    \n",
    "    # identify clues the player holds at start\n",
    "    group['is_held_t0'] = (group[group['start']<3]['is_in_leads']).any()\n",
    "\n",
    "    # add \"stop\" column\n",
    "    group['stop'] = group['start'].shift(-1)\n",
    "    group.loc[group.index[-1], 'stop'] = t_last\n",
    "    \n",
    "    # identify \"adopt\" events \n",
    "    # ie. the row period ends with an adoption change\n",
    "    group['adopt_event'] = group['is_in_leads'] < group.shift(-1)['is_in_leads']\n",
    "    group.loc[group.index[-1], 'adopt_event'] = False\n",
    "\n",
    "    # identify \"forget\" events\n",
    "    group['forget_event'] = group['is_in_leads'] > group.shift(-1)['is_in_leads']\n",
    "    group.loc[group.index[-1], 'forget_event'] = False\n",
    "\n",
    "    return group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_block(block_file):\n",
    "    with open(block_file, 'r') as f:\n",
    "        block = json.load(f)\n",
    "\n",
    "    block_collector = []\n",
    "    for name, game in block.items():\n",
    "        # game level constant calculations\n",
    "        t_final = datetime.strptime(game['finishedAt'], '%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "        t_start = datetime.strptime(game['createdAt'], '%Y-%m-%dT%H:%M:%S.%fZ')\n",
    "        total_time = (t_final-t_start).total_seconds()\n",
    "        \n",
    "        # compute instantaneous hazard factors at each state change\n",
    "        hazard_factors_collector = []\n",
    "        for (active_player_id, g, t) in retrace(game):\n",
    "            hazard_factors_collector += instantaneous_hazard_factors(game, g, t)\n",
    "        hazard_factors = pd.DataFrame(hazard_factors_collector)\n",
    "        \n",
    "        # compute condensed hazard table\n",
    "        hazard_table_collector = []\n",
    "        for i, (eid, group) in enumerate(hazard_factors.groupby('exposure_id')):\n",
    "            hazard_table_collector.append(process_exposure_group(group, total_time))\n",
    "        hazard_table = pd.concat(hazard_table_collector)\n",
    "        hazard_table['is_caveman_game'] = 'caveman' in game['data.gameSetupId']\n",
    "        \n",
    "        block_collector.append(hazard_table)\n",
    "    \n",
    "    # assemble all games in block into single hazard table\n",
    "    block_hazard_table = pd.concat(block_collector)\n",
    "    \n",
    "    # force boolean types to numeric\n",
    "    block_hazard_table *= 1\n",
    "    \n",
    "    # write to file\n",
    "    block_hazard_table_file = block_file.replace('.json', '_hazards.csv')\n",
    "    block_hazard_table.to_csv(block_hazard_table_file)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../results-anonymized/pilot/block_20200505_pilot.json',\n",
       " '../results-anonymized/pilot/block_20200507_pilot.json',\n",
       " '../results-anonymized/pilot/block_20200624_pilot.json',\n",
       " '../results-anonymized/pilot/block_20200626_pilot.json',\n",
       " '../results-anonymized/pilot/block_20200506_pilot.json']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output_dir = \"../results-anonymized/pilot/\"\n",
    "files = glob.glob(output_dir+'block_*_pilot.json')\n",
    "files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:93: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:102: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:105: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:108: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:113: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "/usr/local/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:117: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../results-anonymized/pilot/block_20200505_pilot.json complete\n",
      "['a blue denim jacket', 'DeRolfe Jewelers'] no longer in source YcXuMSvBGNS8TfwyQ\n",
      "['Mitchell', 'a blue Honda Fit'] no longer in source 7ZiYuKHheZ6umhAcG\n",
      "['a blue Honda Fit', 'a broken grill'] no longer in source Ds9n4eazBrNuMFsGq\n",
      "['the necklace', 'a blowtorch'] no longer in source Ds9n4eazBrNuMFsGq\n",
      "../results-anonymized/pilot/block_20200507_pilot.json complete\n",
      "../results-anonymized/pilot/block_20200624_pilot.json complete\n",
      "../results-anonymized/pilot/block_20200626_pilot.json complete\n",
      "['Bennet', 'a pipe cutter'] no longer in source NBRMZjA7bcAyFxKDm\n",
      "../results-anonymized/pilot/block_20200506_pilot.json complete\n"
     ]
    }
   ],
   "source": [
    "for file in files:\n",
    "    process_block(file)\n",
    "    print(file+\" complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "!say \"analysis complete\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> \u001b[0;32m/Users/jameshoughton/Google Drive/MIT PhD/Factionalism_Research/detective-game-interdependent-diffusion/analysis/helpers.py\u001b[0m(64)\u001b[0;36mretrace\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m     62 \u001b[0;31m    \u001b[0;31m# trace game\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     63 \u001b[0;31m    \u001b[0;31m#t_start = datetime.strptime(game['createdAt'], '%Y-%m-%dT%H:%M:%S.%fZ')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m---> 64 \u001b[0;31m    \u001b[0mround\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mr\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mr\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mgame\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'rounds'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'name'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'response'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     65 \u001b[0;31m    \u001b[0mt_start\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'startTimeAt'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'%Y-%m-%dT%H:%M:%S.%fZ'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\u001b[0;32m     66 \u001b[0;31m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0m\n",
      "ipdb> game['rounds']\n",
      "[]\n",
      "ipdb> game['stages']\n",
      "*** KeyError: 'stages'\n",
      "ipdb> n\n"
     ]
    }
   ],
   "source": [
    "%debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
